## â• Added Projects

_Projects that were recently added to this best-of list._

- <b><a href="https://github.com/cdk/cdk">cdk</a></b> (ğŸ¥‡25 Â·  â­ 430 Â· â•) - The Chemistry Development Kit. <code><a href="https://tldrlegal.com/search?q=LGPL-2.1">LGPL-2.1</a></code> <a href="https://en.wikipedia.org/wiki/Cheminformatics"><code>cheminformatics</code></a> <code>Java</code>
- <b><a href="https://github.com/materialsproject/MPContribs">MPContribs</a></b> (ğŸ¥‡23 Â·  â­ 32 Â· â•) - Platform for materials scientists to contribute and disseminate their materials data through Materials Project. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/Open-Catalyst-Project/ocp/blob/main/DATASET.md">Open Catalyst datasets</a></b> (ğŸ¥‡18 Â·  â­ 450 Â· â•) - The datasets of the Open Catalyst project, OC20, OC22. <code><a href="https://tldrlegal.com/search?q=CC-BY-4.0">CC-BY-4.0</a></code>
- <b><a href="https://github.com/GT4SD/gt4sd-core">GT4SD</a></b> (ğŸ¥‡18 Â·  â­ 230 Â· â•) - GT4SD, an open-source library to accelerate hypothesis generation in the scientific discovery process. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>pre-trained</code> <a href="https://en.wikipedia.org/wiki/Drug_design#Computer-aided_drug_design"><code>drug-discovery</code></a> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a>
- <b><a href="https://github.com/CederGroupHub/chgnet">CHGNet</a></b> (ğŸ¥ˆ18 Â·  â­ 79 Â· ğŸ£) - Pretrained universal neural network potential for charge-informed atomistic modeling https://chgnet.lbl.gov. <code><a href="https://github.com/CederGroupHub/chgnet/blob/main/LICENSE">Custom</a></code> <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><code>MD</code></a> <code>pre-trained</code> <code>electrostatics</code> <code>magnetism</code> <code>structure-relaxation</code>
- <b><a href="https://github.com/QUVA-Lab/escnn">escnn</a></b> (ğŸ¥ˆ17 Â·  â­ 200 Â· â•) - Equivariant Steerable CNNs Library for Pytorch https://quva-lab.github.io/escnn/. <code><a href="https://github.com/QUVA-Lab/escnn/blob/master/LICENSE">Custom</a></code>
- <b><a href="https://github.com/materialsproject/matbench">MatBench</a></b> (ğŸ¥ˆ16 Â·  â­ 77 Â· â•) - Matbench: Benchmarks for materials science property prediction. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>datasets</code> <code>benchmarking</code>
- <b><a href="https://github.com/openmm/NNPOps">NNPOps</a></b> (ğŸ¥ˆ15 Â·  â­ 61 Â· â•) - High-performance operations for neural network potentials. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><code>MD</code></a> <code>C++</code>
- <b><a href="https://github.com/divelab/AIRS/blob/main/Overview/resources.md">AI for Science Resources</a></b> (ğŸ¥‰14 Â·  â­ 220 Â· ğŸ£) - List of resources for AI4Science research, including learning resources. <code><a href="https://tldrlegal.com/search?q=GPL-3.0%20license">GPL-3.0 license</a></code>
- <b><a href="https://github.com/divelab/AIRS">Artificial Intelligence for Science (AIRS)</a></b> (ğŸ¥‰14 Â·  â­ 220 Â· ğŸ£) - Artificial Intelligence for Science (AIRS). <code><a href="https://tldrlegal.com/search?q=GPL-3.0%20license">GPL-3.0 license</a></code> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a> <a href="https://en.wikipedia.org/wiki/Generative_model"><code>generative</code></a> <code>MLIAP</code> <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><code>MD</code></a> <code>ML-DFT</code> <code>ML-WFT</code> <a href="https://en.wikipedia.org/wiki/Biomolecule"><code>biomolecules</code></a>
- <b><a href="https://github.com/openmm/openmm-torch">openmm-torch</a></b> (ğŸ¥ˆ14 Â·  â­ 130 Â· â•) - OpenMM plugin to define forces with neural networks. <code><a href="https://github.com/openmm/openmm-torch#license">Custom</a></code> <code>MLIAP</code> <code>C++</code>
- <b><a href="https://github.com/openmm/spice-dataset">SPICE</a></b> (ğŸ¥ˆ14 Â·  â­ 89 Â· â•) - A collection of QM data for training potential functions. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>MLIAP</code> <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><code>MD</code></a>
- <b><a href="https://github.com/materialsproject/pyrho">mp-pyrho</a></b> (ğŸ¥‰14 Â·  â­ 27 Â· â•) -  <code><a href="https://github.com/materialsproject/pyrho">Custom</a></code> <code>ML-DFT</code>
- <b><a href="https://github.com/drcassar/glasspy">GlassPy</a></b> (ğŸ¥ˆ13 Â·  â­ 14 Â· â•) - Python module for scientists working with glass materials. <code><a href="http://bit.ly/2M0xdwT">GPL-3.0</a></code>
- <b><a href="https://github.com/materialsintelligence/mat2vec">mat2vec</a></b> (ğŸ¥ˆ12 Â·  â­ 590 Â· â•) - Supplementary Materials for Tshitoyan et al. Unsupervised word embeddings capture latent knowledge from materials.. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a>
- <b><a href="https://github.com/jparkhill/TensorMol">TensorMol</a></b> (ğŸ¥ˆ12 Â·  â­ 260 Â· ğŸ’€) - Tensorflow + Molecules = TensorMol. <code><a href="http://bit.ly/2M0xdwT">GPL-3.0</a></code> <code>single-paper</code>
- <b><a href="https://github.com/openmm/openmm-ml">OpenMM-ML</a></b> (ğŸ¥‰10 Â·  â­ 50 Â· â•) - High level API for using machine learning models in OpenMM simulations. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>MLIAP</code>
- <b><a href="https://github.com/HSE-LAMBDA/ai4material_design">ai4material_design</a></b> (ğŸ¥ˆ10 Â·  â­ 1 Â· â•) - Code for Kazeev, N., Al-Maeeni, A.R., Romanov, I. et al. Sparse representation for machine learning the properties of.. <code><a href="http://bit.ly/3nYMfla">Apache-2</a></code> <code>pre-trained</code> <a href="https://en.wikipedia.org/wiki/Crystallographic_defect"><code>material-defect</code></a>
- <b><a href="https://github.com/ehoogeboom/e3_diffusion_for_molecules">EDM</a></b> (ğŸ¥‰9 Â·  â­ 290 Â· ğŸ’€) - E(3) Equivariant Diffusion Model for Molecule Generation in 3D. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/biklooost/PROPhet">PROPhet</a></b> (ğŸ¥ˆ9 Â·  â­ 59 Â· ğŸ’€) - PROPhet is a code to integrate machine learning techniques with first-principles quantum chemistry approaches. <code><a href="http://bit.ly/2M0xdwT">GPL-3.0</a></code> <code>MLIAP</code> <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><code>MD</code></a> <code>single-paper</code> <code>C++</code>
- <b><a href="https://github.com/emilemathieu/escnn_jax">escnn_jax</a></b> (ğŸ¥‰8 Â·  â­ 21 Â· ğŸ£) - Equivariant Steerable CNNs Library for Pytorch https://quva-lab.github.io/escnn/. <code><a href="https://github.com/emilemathieu/escnn_jax/blob/master/LICENSE">Custom</a></code>
- <b><a href="https://github.com/lantunes/skipatom">SkipAtom</a></b> (ğŸ¥ˆ8 Â·  â­ 21 Â· ğŸ’€) - Distributed representations of atoms, inspired by the Skip-gram model. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/libAtoms/workflow">wfl</a></b> (ğŸ¥‰8 Â·  â­ 13 Â· â•) - Workflow is a Python toolkit for building interatomic potential creation and atomistic simulation workflows. <code>Unlicensed</code> <code>workflows</code> <a href="https://en.wikipedia.org/wiki/High-throughput_computing"><code>HTC</code></a>
- <b><a href="https://github.com/atomicarchitects/equiformer_v2">EquiformerV2</a></b> (ğŸ¥‰6 Â·  â­ 62 Â· ğŸ£) - [arXiv23] EquiformerV2: Improved Equivariant Transformer for Scaling to Higher-Degree Representations. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/aimat-lab/graph_attention_student">MEGAN</a></b> (ğŸ¥ˆ6 Â·  â­ 1 Â· â•) - Minimal implementation of graph attention student model architecture. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence"><code>XAI</code></a> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a>
- <b><a href="https://github.com/tensorfieldnetworks/tensorfieldnetworks">tensorfieldnetworks</a></b> (ğŸ¥‰5 Â·  â­ 140 Â· ğŸ’€) -  <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/aced-differentiate/EquivariantOperators.jl">EquivariantOperators.jl</a></b> (ğŸ¥‰5 Â·  â­ 17 Â· ğŸ’¤) -  <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>Julia</code>
- <b><a href="https://github.com/drcassar/SciGlass">SciGlass</a></b> (ğŸ¥‰5 Â·  â­ 6 Â· â•) - The database contains a vast set of data on the properties of glass materials. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/lantunes/CraTENet">CraTENet</a></b> (ğŸ¥‰5 Â·  â­ 6 Â· â•) - An attention-based deep neural network for thermoelectric transport properties. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/Transport_phenomena"><code>transport-phenomena</code></a>
- <b><a href="https://github.com/aced-differentiate/closed-loop-acceleration-benchmarks">closed-loop-acceleration-benchmarks</a></b> (ğŸ¥ˆ5 Â· â•) - Data and scripts in support of the publication By how much can closed-loop frameworks accelerate computational.. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://www.psik2022.net/program/symposia#h.p_hM6hJbQD9dex"><code>materials-discovery</code></a> <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)"><code>active-learning</code></a> <code>single-paper</code>
- <b><a href="https://github.com/aced-differentiate/closed-loop-acceleration-benchmarks">Closed-loop acceleration benchmarks</a></b> (ğŸ¥ˆ5 Â· â•) - Data and scripts in support of the publication By how much can closed-loop frameworks accelerate computational.. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://www.psik2022.net/program/symposia#h.p_hM6hJbQD9dex"><code>materials-discovery</code></a> <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)"><code>active-learning</code></a> <code>single-paper</code>
- <b><a href="https://github.com/msg-byu/ML-for-CurieTemp-Predictions">ML-for-CurieTemp-Predictions</a></b> (ğŸ¥‰5 Â· ğŸ£) - Machine Learning Predictions of High-Curie-Temperature Materials. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>single-paper</code> <code>magnetism</code>
- <b><a href="https://github.com/CitrineInformatics-ERD-public/linear-vs-blackbox">Linear vs blackbox</a></b> (ğŸ¥‰4 Â· ğŸ’¤) - Code and data related to the publication: Interpretable models for extrapolation in scientific machine learning. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/Explainable_artificial_intelligence"><code>XAI</code></a> <code>single-paper</code> <a href="https://en.wikipedia.org/wiki/Feature_engineering"><code>rep-eng</code></a>
- <b><a href="https://github.com/idocx/Atom2Vec">Atom2Vec</a></b> (ğŸ¥‰3 Â·  â­ 24 Â· ğŸ’€) - Atom2Vec: a simple way to describe atoms for machine learning. <code>Unlicensed</code>
- <b><a href="https://github.com/CitrineInformatics-ERD-public/sl_discovery">sl_discovery</a></b> (ğŸ¥‰3 Â·  â­ 5 Â· ğŸ’¤) - Data processing and models related to Quantifying the performance of machine learning models in materials discovery. <code><a href="http://bit.ly/3nYMfla">Apache-2</a></code> <a href="https://www.psik2022.net/program/symposia#h.p_hM6hJbQD9dex"><code>materials-discovery</code></a> <code>single-paper</code>
- <b><a href="https://github.com/jeherr/element-encoder">Element encoder</a></b> (ğŸ¥‰3 Â·  â­ 5 Â· ğŸ’€) - Autoencoder neural network to compress properties of atomic species into a vector representation. <code><a href="http://bit.ly/2M0xdwT">GPL-3.0</a></code> <code>single-paper</code>
- <b><a href="https://github.com/siddarthachar/deepcdp">DeepCDP</a></b> (ğŸ¥‰3 Â·  â­ 2 Â· â•) - DeepCDP: Deep learning Charge Density Prediction. <code>Unlicensed</code>
- <b><a href="https://ma.issp.u-tokyo.ac.jp/en/">MateriApps</a></b> (â•) -  <code>Unlicensed</code>

