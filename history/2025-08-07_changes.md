## ğŸ“ˆ Trending Up

_Projects that have a higher project-quality score compared to the last update. There might be a variety of reasons, such as increased downloads or code activity._

- <b><a href="https://github.com/aiqm/torchani">TorchANI</a></b> (ğŸ¥‡25 Â·  â­ 500 Â· ğŸ“ˆ) - Accurate Neural Network Potential on PyTorch. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/ACEsuit/mace-foundations">MACE-FOUNDATION models</a></b> (ğŸ¥ˆ19 Â·  â­ 820 Â· ğŸ“ˆ) - MACE foundation models (MP, OMAT, Matpes). <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>ML-IAP</code> <code>pretrained</code> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a> <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><code>MD</code></a>
- <b><a href="https://github.com/blaiszik/awesome-matchem-datasets">Awesome Materials & Chemistry Datasets</a></b> (ğŸ¥ˆ12 Â·  â­ 200 Â· ğŸ£) - A curated list of the most useful datasets in materials science and chemistry for training machine learning and AI.. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>datasets</code> <a href="https://en.wikipedia.org/wiki/Experimental_physics"><code>experimental-data</code></a> <code>literature-data</code> <a href="https://en.wikipedia.org/wiki/Proprietary_software"><code>proprietary</code></a>
- <b><a href="https://github.com/ulissigroup/finetuna">Finetuna</a></b> (ğŸ¥‰10 Â·  â­ 56 Â· ğŸ’€) - Active Learning for Machine Learning Potentials. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/lcmd-epfl/Q-stack">Q-stack</a></b> (ğŸ¥ˆ9 Â·  â­ 18 Â· ğŸ“ˆ) - Stack of codes for dedicated pre- and post-processing tasks for Quantum Machine Learning (QML). <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/Excited_state"><code>excited-states</code></a> <code>general-tool</code>

## ğŸ“‰ Trending Down

_Projects that have a lower project-quality score compared to the last update. There might be a variety of reasons such as decreased downloads or code activity._

- <b><a href="https://github.com/janosh/pymatviz">pymatviz</a></b> (ğŸ¥ˆ18 Â·  â­ 260 Â· ğŸ“‰) - A toolkit for visualizations in materials informatics. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>general-tool</code> <code>probabilistic</code>
- <b><a href="https://github.com/orbital-materials/orb-models">Orb Models</a></b> (ğŸ¥ˆ16 Â·  â­ 460 Â· ğŸ“‰) - ORB forcefield models from Orbital Materials. <code><a href="https://github.com/orbital-materials/orb-models/blob/main/LICENSE">Custom</a></code> <code>ML-IAP</code> <code>pretrained</code>
- <b><a href="https://github.com/microsoft/mattersim">MatterSim</a></b> (ğŸ¥‰15 Â·  â­ 440 Â· ğŸ“‰) - MatterSim: A deep learning atomistic model across elements, temperatures and pressures. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>ML-IAP</code> <a href="https://en.wikipedia.org/wiki/Active_learning_(machine_learning)"><code>active-learning</code></a> <a href="https://en.wikipedia.org/wiki/Multimodal_learning"><code>multimodal</code></a> <a href="https://en.wikipedia.org/wiki/Phase_transition"><code>phase-transition</code></a> <code>pretrained</code>
- <b><a href="https://github.com/Radical-AI/torch-sim">TorchSim</a></b> (ğŸ¥ˆ15 Â·  â­ 260 Â· ğŸ£) - Torch-native, batchable, atomistic simulation. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/High-throughput_computing"><code>HTC</code></a> <a href="https://www.google.com/search?q=universal+interatomic+potential"><code>UIP</code></a> <code>ML-IAP</code> <a href="https://www.psik2022.net/program/symposia#h.p_hM6hJbQD9dex"><code>structure-optimization</code></a>
- <b><a href="https://github.com/materialsproject/pyrho">mp-pyrho</a></b> (ğŸ¥‰13 Â·  â­ 40 Â· ğŸ’¤) - Tools for re-griding volumetric quantum chemistry data for machine-learning purposes. <code><a href="https://github.com/materialsproject/pyrho">Custom</a></code> <code>ML-DFT</code>

