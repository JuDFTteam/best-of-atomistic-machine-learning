## ğŸ“ˆ Trending Up

_Projects that have a higher project-quality score compared to the last update. There might be a variety of reasons, such as increased downloads or code activity._

- <b><a href="https://github.com/openkim/kliff">KLIFF</a></b> (ğŸ¥ˆ18 Â·  â­ 35 Â· ğŸ“ˆ) - KIM-based Learning-Integrated Fitting Framework for interatomic potentials. <code><a href="https://tldrlegal.com/search?q=LGPL-2.1">LGPL-2.1</a></code> <code>probabilistic</code> <code>workflows</code>
- <b><a href="https://github.com/ur-whitelab/chemcrow-public">ChemCrow</a></b> (ğŸ¥ˆ16 Â·  â­ 730 Â· ğŸ“ˆ) - Open source package for the accurate solution of reasoning-intensive chemical tasks. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/Large_language_model#Agency"><code>ai-agent</code></a>
- <b><a href="https://github.com/Radical-AI/torch-sim">TorchSim</a></b> (ğŸ¥ˆ16 Â·  â­ 170 Â· ğŸ£) - Torch-native, batchable, atomistic simulation. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/High-throughput_computing"><code>HTC</code></a> <a href="https://www.google.com/search?q=universal+interatomic+potential"><code>UIP</code></a> <code>ML-IAP</code> <a href="https://www.psik2022.net/program/symposia#h.p_hM6hJbQD9dex"><code>structure-optimization</code></a>
- <b><a href="https://github.com/lanl/hippynn">hippynn</a></b> (ğŸ¥ˆ13 Â·  â­ 76 Â· ğŸ“ˆ) - python library for atomistic machine learning. <code><a href="https://github.com/lanl/hippynn/blob/main/LICENSE.txt">Custom</a></code> <code>workflows</code>
- <b><a href="https://github.com/deepmodeling/dftio">dftio</a></b> (ğŸ¥ˆ8 Â·  â­ 8 Â· ğŸ“ˆ) - dftio is to assist machine learning communities to transcript DFT output into a format that is easy to read or used by.. <code><a href="http://bit.ly/37RvQcA">LGPL-3.0</a></code> <code>data-structures</code> <code>workflows</code>

## ğŸ“‰ Trending Down

_Projects that have a lower project-quality score compared to the last update. There might be a variety of reasons such as decreased downloads or code activity._

- <b><a href="https://github.com/ppdebreuck/modnet">MODNet</a></b> (ğŸ¥‡16 Â·  â­ 91 Â· ğŸ“‰) - MODNet: a framework for machine learning materials properties. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>pretrained</code> <code>small-data</code> <a href="https://en.wikipedia.org/wiki/Transfer_learning"><code>transfer-learning</code></a>

## â• Added Projects

_Projects that were recently added to this best-of list._

- <b><a href="https://thegardens.ai/">Garden</a></b> (ğŸ¥‡20 Â·  â­ 26 Â· â•) - FAIR AI/ML Model Publishing Framework. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>model-repository</code>
- <b><a href="https://github.com/NVIDIA/cuEquivariance">cuEquivariance</a></b> (ğŸ¥‡19 Â·  â­ 210 Â· ğŸ£) - cuEquivariance is a math library that is a collective of low-level primitives and tensor ops to accelerate widely-used.. <code><a href="http://bit.ly/3nYMfla">Apache-2</a></code> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a>
- <b><a href="https://github.com/argonne-lcf/ai-science-training-series">Introduction to AI-driven Science on Supercomputers: A Student Training Series</a></b> (ğŸ¥ˆ11 Â·  â­ 220 Â· â•) -  <code>Unlicensed</code> <code>general-ml</code> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a> <a href="https://en.wikipedia.org/wiki/Language_model"><code>language-models</code></a>
- <b><a href="https://github.com/PASSIONLab/OpenEquivariance">OpenEquivariance</a></b> (ğŸ¥‰10 Â·  â­ 47 Â· â•) - OpenEquivariance: a fast, open-source GPU JIT kernel generator for the Clebsch-Gordon Tensor Product. <code><a href="http://bit.ly/3aKzpTv">BSD-3</a></code> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a>

