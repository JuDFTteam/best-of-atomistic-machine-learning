## ğŸ“ˆ Trending Up

_Projects that have a higher project-quality score compared to the last update. There might be a variety of reasons, such as increased downloads or code activity._

- <b><a href="https://github.com/jax-md/jax-md">JAX-MD</a></b> (ğŸ¥‡25 Â·  â­ 1.3K Â· ğŸ“ˆ) - Differentiable, Hardware Accelerated, Molecular Dynamics. <code><a href="http://bit.ly/3nYMfla">Apache-2</a></code>
- <b><a href="https://github.com/CederGroupHub/chgnet">CHGNet</a></b> (ğŸ¥ˆ23 Â·  â­ 330 Â· ğŸ“ˆ) - Pretrained universal neural network potential for charge-informed atomistic modeling https://chgnet.lbl.gov. <code><a href="https://github.com/CederGroupHub/chgnet/blob/main/LICENSE">Custom</a></code> <code>ML-IAP</code> <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><code>MD</code></a> <code>pretrained</code> <a href="https://en.wikipedia.org/wiki/Electrostatics"><code>electrostatics</code></a> <code>magnetism</code> <code>structure-relaxation</code>
- <b><a href="https://github.com/torchmd/torchmd-net">TorchMD-NET</a></b> (ğŸ¥‡22 Â·  â­ 430 Â· ğŸ“ˆ) - Training neural network potentials. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/Molecular_dynamics"><code>MD</code></a> <a href="https://en.wikipedia.org/wiki/Feature_learning"><code>rep-learn</code></a> <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)"><code>transformer</code></a> <code>pretrained</code>
- <b><a href="https://github.com/divelab/DIG">DIG: Dive into Graphs</a></b> (ğŸ¥ˆ21 Â·  â­ 2K Â· ğŸ’€) - A library for graph deep learning research. <code><a href="http://bit.ly/2M0xdwT">GPL-3.0</a></code>
- <b><a href="https://github.com/metatensor/featomic">Featomic</a></b> (ğŸ¥ˆ15 Â·  â­ 73 Â· ğŸ“ˆ) - Computing representations for atomistic machine learning. <code><a href="http://bit.ly/3aKzpTv">BSD-3</a></code> <code>Rust</code> <code>C++</code>

## ğŸ“‰ Trending Down

_Projects that have a lower project-quality score compared to the last update. There might be a variety of reasons such as decreased downloads or code activity._

- <b><a href="https://github.com/atomistic-machine-learning/schnetpack">SchNetPack</a></b> (ğŸ¥‡26 Â·  â­ 870 Â· ğŸ“‰) - SchNetPack - Deep Neural Networks for Atomistic Systems. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/materialsproject/MPContribs">MPContribs</a></b> (ğŸ¥‡25 Â·  â­ 39 Â· ğŸ“‰) - Platform for materials scientists to contribute and disseminate their materials data through Materials Project. <code><a href="http://bit.ly/34MBwT8">MIT</a></code>
- <b><a href="https://github.com/google-deepmind/kfac-jax">KFAC-JAX</a></b> (ğŸ¥‡20 Â·  â­ 280 Â· ğŸ“‰) - Second Order Optimization and Curvature Estimation with K-FAC in JAX. <code><a href="http://bit.ly/3nYMfla">Apache-2</a></code>
- <b><a href="https://github.com/openml/OpenML">OpenML</a></b> (ğŸ¥‡19 Â·  â­ 710 Â· ğŸ“‰) - Open Machine Learning. <code><a href="http://bit.ly/3aKzpTv">BSD-3</a></code> <code>datasets</code>
- <b><a href="https://github.com/ACEsuit/Polynomials4ML.jl">Polynomials4ML.jl</a></b> (ğŸ¥ˆ13 Â·  â­ 13 Â· ğŸ“‰) - Polynomials for ML: fast evaluation, batching, differentiation. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <code>Julia</code>

