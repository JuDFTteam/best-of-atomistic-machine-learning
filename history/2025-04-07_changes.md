## ğŸ“ˆ Trending Up

_Projects that have a higher project-quality score compared to the last update. There might be a variety of reasons, such as increased downloads or code activity._

- <b><a href="https://github.com/Radical-AI/torch-sim">TorchSim</a></b> (ğŸ¥ˆ15 Â·  â­ 150 Â· ğŸ£) - Torch-native, batchable, atomistic simulation. <code><a href="http://bit.ly/34MBwT8">MIT</a></code> <a href="https://en.wikipedia.org/wiki/High-throughput_computing"><code>HTC</code></a> <a href="https://www.google.com/search?q=universal+interatomic+potential"><code>UIP</code></a> <code>ML-IAP</code> <a href="https://www.psik2022.net/program/symposia#h.p_hM6hJbQD9dex"><code>structure-optimization</code></a>
- <b><a href="https://github.com/lamm-mit/Graph-Aware-Transformers">Graph-Aware-Transformers</a></b> (ğŸ¥‰6 Â·  â­ 56 Â· ğŸ£) - Graph-Aware Attention for Adaptive Dynamics in Transformers. <code><a href="http://bit.ly/3nYMfla">Apache-2</a></code> <a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)"><code>transformer</code></a> <code>graph-data</code> <code>pretrained</code> <code>single-paper</code>
- <b><a href="{}">LapNet</a></b> (ğŸ¥‰2 Â· ğŸ“ˆ) -  <code><a href="http://bit.ly/3nYMfla">Apache-2</a></code>
- <b><a href="{}">LapJAX</a></b> (ğŸ¥‰2 Â· ğŸ“ˆ) -  <code><a href="http://bit.ly/34MBwT8">MIT</a></code>

